<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multi-texture synthesis using genome-coded signals for a NCA.">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Multi-Texture Synthesis through signal responsive NCA</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Multi-Texture Synthesis through signal responsive Neural Cellular Automata</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Catrina Mirela-Magdalena</span>
                <!-- <sup>1</sup> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Scientific coordinator: Lect. dr. Baicoianu Alexandra, Lect. dr. Plajer Cristina Ioana</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/NCA - Results.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2> -->
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p> Neural cellular automata (NCA) have been proven effective in a variety of areas, with numerous
            biologically inspired applications. We believe that NCAs fit perfectly to the task of generating 
            textures: they model global patterns from local interactions governed by uniform, consistent rules, 
            enhancing structured, near-regular patterns. Therefore, this project aims to increase the usability of 
            NCAs in texture synthesis by addressing a shortcoming in current NCA architectures for texture generation:
            the necessity for one trained NCA per texture. Thus we train one NCA to evolve into multiple textures provided
            by example. Our solution relies on providing texture information in the seed, as a genomically-coded internal 
            signal that the NCA interprets and yield the expected texture. Particularly, we define a few hidden channels of 
            the cell's state to be genome channels. 
          </p>
          <p> Employing this architecture leads to an extended range of behaviours exhibited by our NCA. Generating 
            multiple textures from one NCA allows us to test interpolation behaviours between learned examples and grafting
            techniques, while enhancing the well-known NCA property of regeneration, further emphasizing the editability of
            generated textures and the possibility of multiple textures joining and coexisting in one automaton. We address
            questions relating the extent to which our NCA uses the genomic information and proper loss function selection 
            based on the properties of selected example images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <h2 class="title is-3"> Results </h2>
    
    <h2 class="title is-4">Generation</h2>
    <p> Below we visualize the evolution of a neural cellular automata (NCA), with 4270 parameters, 
    trained on 8 different textures. The size of the generated textures is 256 x 256, whereas the examples 
    fed during training are of resolution 128 x 128. </p>
    
    <img src="./static/images/Texture-to-genome.jpg"
      class="interpolation-image"
      alt="Interpolate start reference image."/>
    <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
      <source src="./static/videos/cmp-8Textures256-small.mp4"
              type="video/mp4">
    </video>

    

    <div class="columns is-centered">
      
      <div class="column content">
        <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/cmp-4-nolabel.mp4"
                  type="video/mp4">
        </video>
        <p> 
          <p class="mt-4"> We observe the evolution of a NCA trained on 4 different textures. </p>
      </div>

      <div class="column content">
        <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/cmp-similar-4.mp4"
                  type="video/mp4">
        </video>
        <p> We observe the evolution of a NCA trained on 4 similar textures. It is more unstable,
        after a large number of steps the genome information seems to be lost and the textures
        converge towards other genomes. </p>
      </div>

    </div>

    <!-- <div class="columns is-centered"> -->
      

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      / Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div> -->
    <!-- </div> -->
    <!--/ Matting. -->
    
    <h2 class="title is-4">Regeneration</h2>
    <div class="columns is-centered">
      
      <div class="column content">
        <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/video-256-g0_0_0-regeneration_genome000-sppeed1-80.mp4"
                  type="video/mp4">
        </video>
        <p> Behaviour before adjusting the training methodology to enhance regeneration. </p>
      </div>
      <div class="column content">
        <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/video-256-g1_0-regeneration_genome10-spped1-80.mp4"
                  type="video/mp4">
        </video>
        <p> Behaviour after adjusting the methodology.</p>
      </div>
      <div class="column content">
        <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/video-256-g1_1-regeneration_genome11-speed-180.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">New behaviour</h2>

        <!-- Interpolating. -->
        <h3 class="title is-5">Interpolation</h3>
        <div class="content has-text-justified">
          <p>
            Given the added genome channels, we can nou interpolate between textures known by the same automaton:
          </p>
          <img src="./static/images/NCA - LFC+Lic - interpolation-first-example.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
          <img src="./static/images/NCA - LFC+Lic - interpolation-more-examples.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        
        <!-- <div class="columns is-centered">
      
          <div class="column content">
            <img src="./static/images/interp-small.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
          </div>
    
          <div class="column content">
            <img src="./static/images/interp-small2.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            
          </div> -->
    
        <!-- </div> -->
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Grafting</h3>
        <div class="content has-text-justified">
          <p>
            Grafting allows us to generate multiple textures through the same instance. Cells are initialized with wanted genomes, 
            they evolve and interact.
          </p>
        </div>
        <div class="columns is-centered">
      
          <div class="column content">
            <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/grafting1.mp4"
                      type="video/mp4">
            </video>
          </div>
    
          <div class="column content">
            <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/grafting2.mp4"
                      type="video/mp4">
            </video>
            <!-- <p> We observe the evolution of a NCA trained on 4 similar textures. It is more unstable,
            after a large number of steps the genome information seems to be lost and the textures
            converge towards other genomes. </p> -->
          </div>

          <div class="column content">
            <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/grafting3.mp4"
                      type="video/mp4">
            </video>
            <!-- <p> We observe the evolution of a NCA trained on 4 similar textures. It is more unstable,
            after a large number of steps the genome information seems to be lost and the textures
            converge towards other genomes. </p> -->
          </div>

          <div class="column content">
            <video poster="" id="4-together" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/grafting4.mp4"
                      type="video/mp4">
            </video>
            <!-- <p> We observe the evolution of a NCA trained on 4 similar textures. It is more unstable,
            after a large number of steps the genome information seems to be lost and the textures
            converge towards other genomes. </p> -->
          </div>
    
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->

    <!-- Discussions -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Discussions</h2>

        <h2 class="title is-4">Preservation of the genome</h2>
        <p> Given the diversity of the generated textures in our experiments, a question
          arises: does the automaton know how to preserve and generate based solely
          on the perception stage and vicinity's properties, or does it also maintain the
          genome information to gather stability?
          </p>
  
          <img src="./static/images/NCA - LFC+Lic - Vicinity-Evolution.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>

      </div>
    </div>
    <!-- /Discussions -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Arhitecture details</h2>
        <h2 class="title is-4">NCA Pass</h2>
        
        
        <img src="./static/images/NCA - Pass.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>

          
          <p>A NCA pass is illustrated above and consists of 2 major steps: </p>
          <ul class="mb-3">
            <li><b>perception: </b> employs 4 kernels Identity, Sobelx, Sobely Laplacian
               to convolute over each channel of the NCA state and offer the perception values for the next stage. </li>
            <li><b>state processing: </b> done using a Neural Network with one hidden layer and kernels of size
            1x1, simulating the per-cell, independent, state processing. </li>
          </ul>

          <h2 class="title is-4 mt-4">Loss function</h2>
          <div style="display: flex; align-items: center; flex-direction: column;">
            <img src="./static/images/Loss-vgg.png"
            class="interpolation-image"
            alt="Loss vgg."/>
              <p class="mt-4" style="align-self: flex-start;"> The Sliced Wasserstein Loss is calculated
              on feature maps extracted from a VGG16 pass for the example and generated image. </p>
          </div>

          <div style="display: flex; align-items: center; flex-direction: column;">
            <img src="./static/images/NCA - Loss meaning.jpg"
              class="interpolation-image"
              alt="Loss meaning."/>
              <!-- <p class="mt-4" style="align-self: flex-start;"> </p> -->
            <p class="mt-4" style="align-self: flex-start;"> It is calculated between each feature maps
            by projecting the feature vectors onto multiple random directions and calculating the 1D OT
            distances between the obtained sorted scalars using MSE. </p>
          </div>

      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>This website is used to provide additional materials for the AFCO presentation and is 
            not a standalone project description.</p>
          <p>
            Website source code is based on the Nerfies project page. If you want to reuse 
            their  <a
            href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
